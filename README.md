# MLP_MNIST

The notebook walks through the MLP (Shallow Neural Network) with a hidden layer of size 1000 units and output layer of 10 units. The notebook provides the computational graph perspective of the MLP by implementing the forward propagation, cost function and backward propagation functions. The network is trained for 10 epochs with a random minibatch size of 5 on the training dataset of size 50,000 images. It is tested on the validation dataset of 10,000 images which achieved an accuracy of 92.73%.
